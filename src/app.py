import streamlit as st
import os
import numpy as np
import requests
from PIL import Image, ImageDraw
import io
import hashlib

# Thi·∫øt l·∫≠p c·∫•u h√¨nh trang
st.set_page_config(
    page_title="Brain Tumor Detection",
    page_icon="üîç",
    layout="wide"
)

# Endpoint API - l·∫•y t·ª´ bi·∫øn m√¥i tr∆∞·ªùng ho·∫∑c s·ª≠ d·ª•ng gi√° tr·ªã m·∫∑c ƒë·ªãnh
API_URL = os.environ.get("API_URL", "http://localhost:8000")

# Ti√™u ƒë·ªÅ v√† m√¥ t·∫£
st.title("Brain Tumor Detection")
st.markdown("Upload an image to detect brain tumors using YOLOv11s model")

# Thanh b√™n
st.sidebar.title("Settings")
confidence = st.sidebar.slider("Confidence Threshold", 0.0, 1.0, 0.5, 0.05)
use_onnx = st.sidebar.checkbox("Use ONNX model (faster inference)", value=True)

# Kh·ªüi t·∫°o session state ƒë·ªÉ l∆∞u cache
if 'prediction_cache' not in st.session_state:
    st.session_state.prediction_cache = {}

# Ki·ªÉm tra xem API c√≥ ƒëang ch·∫°y kh√¥ng
try:
    response = requests.get(f"{API_URL}/")
    if response.status_code == 200:
        st.success("‚úÖ API is running and ready for predictions")
    else:
        st.error("‚ùå API is not responding correctly")
except requests.exceptions.ConnectionError:
    st.error("‚ùå Cannot connect to API. Please make sure the API server is running.")

# C√¥ng c·ª• upload file
uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # T·∫°o kh√≥a cache d·ª±a tr√™n n·ªôi dung file v√† c√†i ƒë·∫∑t
    file_bytes = uploaded_file.getvalue()
    settings_str = f"{confidence}_{use_onnx}"
    cache_key = hashlib.md5(file_bytes + settings_str.encode()).hexdigest()
    
    # Chuy·ªÉn ƒë·ªïi file ƒë√£ upload th√†nh ·∫£nh
    image = Image.open(uploaded_file)
    
    # Resize ·∫£nh tr∆∞·ªõc khi g·ª≠i ƒë·∫øn API ƒë·ªÉ gi·∫£m th·ªùi gian truy·ªÅn
    max_size = 640  # K√≠ch th∆∞·ªõc t·ªëi ƒëa ph√π h·ª£p v·ªõi YOLO
    orig_width, orig_height = image.size
    
    # Ch·ªâ resize n·∫øu ·∫£nh l·ªõn h∆°n k√≠ch th∆∞·ªõc t·ªëi ƒëa
    if max(orig_width, orig_height) > max_size:
        if orig_width > orig_height:
            new_width = max_size
            new_height = int(orig_height * (max_size / orig_width))
        else:
            new_height = max_size
            new_width = int(orig_width * (max_size / orig_height))
        
        # L∆∞u t·ª∑ l·ªá ƒë·ªÉ kh√¥i ph·ª•c bounding box sau n√†y
        scale_x = orig_width / new_width
        scale_y = orig_height / new_height
        
        # Resize ·∫£nh
        image_resized = image.resize((new_width, new_height), Image.LANCZOS)
    else:
        image_resized = image
        scale_x = scale_y = 1.0
    
    # T·∫°o c·ªôt cho ·∫£nh g·ªëc v√† ·∫£nh ƒë√£ x·ª≠ l√Ω
    col1, col2 = st.columns(2)
    
    # Hi·ªÉn th·ªã ·∫£nh g·ªëc trong c·ªôt 1
    with col1:
        st.subheader("Original Image")
        st.image(image, caption="Uploaded Image", use_container_width=True)
    
    # Ki·ªÉm tra cache nh∆∞ng kh√¥ng hi·ªÉn th·ªã th√¥ng b√°o ·ªü ƒë√¢y
    if cache_key in st.session_state.prediction_cache:
        predictions = st.session_state.prediction_cache[cache_key]
        error_message = None
        is_from_cache = True
    else:
        is_from_cache = False
        # Hi·ªÉn th·ªã spinner trong khi ƒëang x·ª≠ l√Ω
        with st.spinner('Detecting tumors...'):
            # Chu·∫©n b·ªã ·∫£nh cho API request - t·ªëi ∆∞u ƒë·ªãnh d·∫°ng
            img_byte_arr = io.BytesIO()
            
            # Chuy·ªÉn ƒë·ªïi t·ª´ RGBA sang RGB n·∫øu c·∫ßn
            if image_resized.mode == 'RGBA':
                image_resized_rgb = image_resized.convert('RGB')
            else:
                image_resized_rgb = image_resized
                
            image_resized_rgb.save(img_byte_arr, format='JPEG', quality=85)
            img_byte_arr = img_byte_arr.getvalue()

            try:
                # T·∫°o request d·ª± ƒëo√°n ƒë·∫øn API v·ªõi tham s·ªë ONNX
                files = {"file": ("image.jpg", img_byte_arr, "image/jpeg")}
                params = {"use_onnx": "true" if use_onnx else "false"}
                
                # ƒêo th·ªùi gian ph·∫£n h·ªìi
                import time
                start_time = time.time()
                
                response = requests.post(f"{API_URL}/predict", files=files, params=params)
                
                processing_time = time.time() - start_time
                
                if response.status_code == 200:
                    response_data = response.json()
                    
                    # Ki·ªÉm tra xem c√≥ th√¥ng b√°o l·ªói trong ph·∫£n h·ªìi kh√¥ng
                    error_message = response_data.get("error", None)
                    if "detail" in response_data:
                        error_message = response_data["detail"]
                    
                    predictions = response_data.get("predictions", [])
                    
                    # L∆∞u k·∫øt qu·∫£ v√†o cache ch·ªâ khi kh√¥ng c√≥ l·ªói
                    if not error_message:
                        st.session_state.prediction_cache[cache_key] = predictions
                else:
                    st.error(f"Error from API: {response.text}")
                    predictions = []
                    error_message = response.text
            except requests.exceptions.RequestException as e:
                st.error(f"Error communicating with API: {str(e)}")
                predictions = []
                error_message = str(e)
    
    # T·∫°o b·∫£n sao c·ªßa ·∫£nh ƒë·ªÉ v·∫Ω l√™n
    result_image = image.copy()
    draw = ImageDraw.Draw(result_image)
    
    # X·ª≠ l√Ω k·∫øt qu·∫£ v√† v·∫Ω l√™n ·∫£nh
    if predictions:
        for pred in predictions:
            if pred["confidence"] >= confidence:
                # L·∫•y t·ªça ƒë·ªô bounding box v√† scale l·∫°i v·ªÅ k√≠ch th∆∞·ªõc ·∫£nh g·ªëc
                bbox = pred["bbox"]
                x1, y1, x2, y2 = bbox
                
                # Scale t·ªça ƒë·ªô v·ªÅ k√≠ch th∆∞·ªõc ·∫£nh g·ªëc n·∫øu ƒë√£ resize
                if scale_x != 1.0 or scale_y != 1.0:
                    x1 *= scale_x
                    y1 *= scale_y
                    x2 *= scale_x
                    y2 *= scale_y
                
                x1, y1, x2, y2 = [int(coord) for coord in [x1, y1, x2, y2]]
                
                # V·∫Ω h√¨nh ch·ªØ nh·∫≠t l√™n ·∫£nh
                # M√†u d·ª±a tr√™n class (c√≥ th·ªÉ t√πy ch·ªânh)
                colors = {
                    "glioma": (255, 0, 0),      # ƒê·ªè
                    "meningioma": (0, 255, 0),  # Xanh l√°
                    "pituitary": (0, 0, 255),   # Xanh d∆∞∆°ng
                    "notumor": (255, 255, 0)    # V√†ng
                }
                color = colors.get(pred["class"], (255, 0, 0))
                
                # V·∫Ω bounding box
                draw.rectangle([x1, y1, x2, y2], outline=color, width=3)
                
                # Th√™m nh√£n
                label = f"{pred['class']}: {pred['confidence']:.2f}"
                draw.text((x1, y1-15), label, fill=color)
    
    # Hi·ªÉn th·ªã ·∫£nh k·∫øt qu·∫£ trong c·ªôt 2
    with col2:
        st.subheader("Detection Results")
        if predictions:
            st.image(result_image, caption="Detection Results", use_container_width=True)
        else:
            st.info("No tumors detected in the image")
            st.image(image, caption="No tumors detected", use_container_width=True)
    
    # Hi·ªÉn th·ªã th√¥ng tin k·∫øt qu·∫£ b√™n d∆∞·ªõi c·∫£ hai ·∫£nh (ngo√†i columns)
    st.subheader("Detection Information")
    
    # Hi·ªÉn th·ªã th√¥ng b√°o cache ·ªü ƒë√¢y thay v√¨ ·ªü tr√™n
    if is_from_cache:
        st.success("‚úÖ Retrieved result from cache")
    else:
        # Hi·ªÉn th·ªã th·ªùi gian x·ª≠ l√Ω v√† th√¥ng tin model
        if 'processing_time' in locals():
            st.info(f"Processing time: {processing_time:.3f} seconds")
        
        if 'response_data' in locals() and "model_type" in response_data:
            st.success(f"Used {response_data['model_type']} model for inference")
    
    # Hi·ªÉn th·ªã k·∫øt qu·∫£ chi ti·∫øt
    if predictions:
        st.subheader("Detection Details")
        for pred in predictions:
            if pred["confidence"] >= confidence:
                st.write(f"Class: {pred['class']} | Confidence: {pred['confidence']:.2f}")
    
    # Hi·ªÉn th·ªã th√¥ng b√°o l·ªói n·∫øu c√≥
    if 'error_message' in locals() and error_message:
        st.error(f"Error from API: {error_message}")
